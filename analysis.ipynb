{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-22T13:21:46.455727Z",
     "start_time": "2024-06-22T13:21:46.442219Z"
    }
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from support import *"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T13:21:47.026353Z",
     "start_time": "2024-06-22T13:21:46.456726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = [pickle.load(open(f, 'rb')) for f in glob('./result-50p/*.pkl')]\n",
    "results = [item for sublist in results for item in sublist]"
   ],
   "id": "edc575397341becb",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T13:21:47.043936Z",
     "start_time": "2024-06-22T13:21:47.027485Z"
    }
   },
   "cell_type": "code",
   "source": "np.max([r.result for r in results]), np.min([r.result for r in results])",
   "id": "5d936ebce2652f88",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44963, 20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T13:21:47.209308Z",
     "start_time": "2024-06-22T13:21:47.044937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "broad_words = set([word for r in results for word in r.broad_words])\n",
    "narrow_words = set([word for r in results for word in r.narrow_words])\n",
    "broad_words_toi = {word: i for i, word in enumerate(broad_words)}\n",
    "narrow_words_toi = {word: i for i, word in enumerate(narrow_words)}\n",
    "broad_words_ito = {i: word for word, i in broad_words_toi.items()}\n",
    "narrow_words_ito = {i: word for word, i in narrow_words_toi.items()}\n",
    "pickle.dump(broad_words_toi, open('broad_words_toi.pkl', 'wb'))\n",
    "pickle.dump(narrow_words_toi, open('narrow_words_toi.pkl', 'wb'))"
   ],
   "id": "1f6ff8b1198bf49",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T13:21:54.472534Z",
     "start_time": "2024-06-22T13:21:47.211312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = []\n",
    "for r in results:\n",
    "    broad = torch.zeros(len(broad_words))\n",
    "    narrow = torch.zeros(len(narrow_words))\n",
    "    for (word, sel) in zip(r.broad_words, r.broad_sel):\n",
    "        broad[broad_words_toi[word]] = 1 if sel else -1\n",
    "    for (word, sel) in zip(r.narrow_words, r.narrow_sel):\n",
    "        narrow[narrow_words_toi[word]] = 1 if sel else -1\n",
    "    samples.append((\n",
    "        broad.to(torch.float),\n",
    "        narrow.to(torch.float), \n",
    "        torch.tensor([r.result]).to(torch.float)\n",
    "    ))\n",
    "torch.save(samples, 'samples.pt')"
   ],
   "id": "12d6d10bac211a8e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T13:21:55.925975Z",
     "start_time": "2024-06-22T13:21:54.473397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = torch.load('samples.pt')\n",
    "dataloader = DataLoader(samples, batch_size=128, shuffle=True)\n",
    "samples.__len__(), len(broad_words), len(narrow_words)"
   ],
   "id": "bf759c8de230d186",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14472, 127, 608)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T13:21:55.941518Z",
     "start_time": "2024-06-22T13:21:55.927480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_broad, n_narrow):\n",
    "        super(Model, self).__init__()\n",
    "        self.broad = nn.Sequential(\n",
    "            nn.Linear(n_broad, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.narrow = nn.Sequential(\n",
    "            nn.Linear(n_narrow, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 75),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(75, 32),\n",
    "        )\n",
    "        self.combined = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, broad, narrow):\n",
    "        broad = self.broad(broad)\n",
    "        narrow = self.narrow(narrow)\n",
    "        combined = torch.cat((broad, narrow), dim=1)\n",
    "        return self.combined(combined)\n",
    "    \n",
    "model = Model(len(broad_words), len(narrow_words))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()"
   ],
   "id": "920d0963d97fb064",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T13:21:55.958609Z",
     "start_time": "2024-06-22T13:21:55.942988Z"
    }
   },
   "cell_type": "code",
   "source": "losses = []",
   "id": "896cd00e0d461cdd",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-22T13:21:55.960039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in tqdm(range(200)):\n",
    "    los = []\n",
    "    for broad, narrow, result in dataloader:\n",
    "        result = result / 45000\n",
    "        optimizer.zero_grad()\n",
    "        output = model(broad, narrow)\n",
    "        loss = criterion(output, result)\n",
    "        los.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(np.mean(los))\n",
    "plt.plot(np.log(losses))"
   ],
   "id": "41383ab49af5694b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20ec560cb56d4757a83ef31c6d40d699"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "model(torch.ones(1, len(broad_words)), torch.ones(1, len(narrow_words))) * 45000",
   "id": "dda7acdc327f2595",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "model(torch.ones(1, len(broad_words)) * -1, torch.ones(1, len(narrow_words)) * -1) * 45000",
   "id": "971209f2beef4e3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), 'model1.pt')",
   "id": "6b9436cfd238ba9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
